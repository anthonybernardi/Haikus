{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ux-a_weUVGVF"
   },
   "source": [
    "# Train word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Odfuc2xyVCwP",
    "outputId": "b6174a20-5314-44c9-c688-e121d83de2b5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, LSTM, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.losses import Reduction\n",
    "from keras import Input\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6yKDKcTrXx61"
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "HAIKU_BEGIN = \"<h>\"\n",
    "HAIKU_END = \"</h>\"\n",
    "LINE_BEGIN = \"<s>\"\n",
    "LINE_END = \"</s>\"\n",
    "\n",
    "NGRAM_SIZE = 7\n",
    "EMBEDDING_SIZE = 200\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "INPUT_UNITS = (NGRAM_SIZE - 1) * EMBEDDING_SIZE\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "line_structure = {1 : 5,\n",
    "                 2 : 7,\n",
    "                 3 : 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125927\n"
     ]
    }
   ],
   "source": [
    "word_to_syllable = {}\n",
    "\n",
    "with open(\"data/phoneticDictionary.csv\", 'r', encoding='utf_8') as f:\n",
    "    f.readline()\n",
    "    for line in f.readlines():\n",
    "        cols = line.split(',')\n",
    "        word_to_syllable[cols[1].strip(\"\\\"\")] = int(cols[3])\n",
    "print(len(word_to_syllable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qo079uXXWBmR",
    "outputId": "dd5a182f-4d2f-42bc-9682-7f6fdfbb6981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<h>', '<h>', '<h>', '<h>', '<h>', '<h>', '<s>', 'delicate', 'savage', '</s>', '<s>', \"you'll\", 'never', 'hold', 'the', 'cinder', '</s>', '<s>', 'but', 'still', 'you', 'will', 'burn', '</s>', '</h>', '</h>', '</h>', '</h>', '</h>', '</h>'], ['<h>', '<h>', '<h>', '<h>', '<h>', '<h>', '<s>', 'our', 'destination', '</s>', '<s>', 'the', 'skyline', 'of', 'this', 'city', '</s>', '<s>', 'shining', 'horizon', '</s>', '</h>', '</h>', '</h>', '</h>', '</h>', '</h>'], ['<h>', '<h>', '<h>', '<h>', '<h>', '<h>', '<s>', 'a', 'splash', 'and', 'a', 'cry', '</s>', '<s>', 'words', 'pulled', 'from', 'the', 'riverside', '</s>', '<s>', 'dried', 'in', 'the', 'hot', 'sun', '</s>', '</h>', '</h>', '</h>', '</h>', '</h>', '</h>'], ['<h>', '<h>', '<h>', '<h>', '<h>', '<h>', '<s>', 'hurt', 'but', 'poised', 'for', 'war', '</s>', '<s>', 'sturdy', 'in', 'crestfallen', 'slumps', '</s>', '<s>', 'warrior', 'spirit', '</s>', '</h>', '</h>', '</h>', '</h>', '</h>', '</h>'], ['<h>', '<h>', '<h>', '<h>', '<h>', '<h>', '<s>', 'steamy', 'mist', 'rising', '</s>', '<s>', 'rocks', 'receiving', 'downward', 'crash', '</s>', '<s>', 'as', 'the', 'jungle', 'weeps', '</s>', '</h>', '</h>', '</h>', '</h>', '</h>', '</h>']]\n"
     ]
    }
   ],
   "source": [
    "# as per meeting w/ felix, training on whole haiku so it learns the structure\n",
    "# results = lists of tokenized haiku, with poem and line separator tokens:\n",
    "# [[<H>,<S>,stanza 1,</S>,<S>,stanza 2,</S>,<S>,stanza 3,</S>,</H>],...]\n",
    "\n",
    "haiku_loc = \"data/haiku_reddit.txt\"\n",
    "reddit_tokens = []\n",
    "with open(haiku_loc, 'r', encoding='utf-8') as f:\n",
    "  for line in f:\n",
    "    tokens = []\n",
    "    # remove trailing spaces and end-of-poem $/n marker\n",
    "    stanzas = [s.strip(' $\\n') for s in line.split(\"/\")]\n",
    "    tokens += [HAIKU_BEGIN] * (NGRAM_SIZE - 1)\n",
    "    \n",
    "    for stanza in stanzas:\n",
    "      tokens.append(LINE_BEGIN)\n",
    "      # whitespace split rather than NLTK tokenize because I don't know if the\n",
    "      # syllable dictionary has entries for nonword NLTK tokens (eg 'll n't)\n",
    "      tokens.extend(stanza.split())\n",
    "      tokens.append(LINE_END)\n",
    "      \n",
    "    tokens += [HAIKU_END] * (NGRAM_SIZE - 1)\n",
    "    reddit_tokens.append(tokens)\n",
    "\n",
    "print(reddit_tokens[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvnN0vSOeXam"
   },
   "source": [
    "Train embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "81GN5Ue8eZkR"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains a word2vec model on the given sentences. Returns the trained word embeddings as a KeyedVectors object.\n",
    "Function provided from HW4 starter code.\n",
    "\"\"\"\n",
    "def train_model(sentences, sg=1, window_size=5, vector_size=EMBEDDING_SIZE, min_count=1) :\n",
    "  model = Word2Vec(sentences=sentences, vector_size=vector_size, window=window_size, min_count=min_count, sg=sg)\n",
    "  return model.wv\n",
    "\n",
    "reddit_haiku_embs = train_model(reddit_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ds4TEM75hw5u",
    "outputId": "353ab9a7-3fde-47c8-833a-7871b6eaf584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 1, 1, 1, 3, 1444, 3133, 4, 3, 918, 68, 334, 5, 7333, 4, 3, 28, 62, 11, 33, 555, 4, 2, 2, 2, 2, 2, 2], [1, 1, 1, 1, 1, 1, 3, 57, 3134, 4, 3, 5, 2068, 12, 26, 451, 4, 3, 796, 615, 4, 2, 2, 2, 2, 2, 2], [1, 1, 1, 1, 1, 1, 3, 7, 2069, 13, 7, 437, 4, 3, 81, 1568, 36, 5, 7334, 4, 3, 2304, 10, 5, 274, 65, 4, 2, 2, 2, 2, 2, 2], [1, 1, 1, 1, 1, 1, 3, 518, 28, 4983, 16, 506, 4, 3, 3853, 10, 7335, 7336, 4, 3, 2305, 438, 4, 2, 2, 2, 2, 2, 2], [1, 1, 1, 1, 1, 1, 3, 3854, 1114, 538, 4, 3, 1005, 3855, 3135, 1275, 4, 3, 41, 5, 2070, 1569, 4, 2, 2, 2, 2, 2, 2]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(reddit_tokens)\n",
    "encoded = tokenizer.texts_to_sequences(reddit_tokens)\n",
    "\n",
    "print(encoded[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UtX8Q7jvlsbJ"
   },
   "outputs": [],
   "source": [
    "def generate_ngram_training_samples(encoded: list) -> list:\n",
    "    '''\n",
    "    Takes the encoded data (list of lists) and \n",
    "    generates the training samples out of it.\n",
    "    Parameters:\n",
    "    up to you, we've put in what we used\n",
    "    but you can add/remove as needed\n",
    "    return: \n",
    "    tuple of (training_x, training_y) in the format [[1, 2, 3], [2, 3, 2], ...] and [2, 4, ...]\n",
    "    '''\n",
    "    training_x = []\n",
    "    training_y = []\n",
    "\n",
    "    for sentence in encoded:\n",
    "      for i in range(len(sentence) - NGRAM_SIZE + 1):\n",
    "        training_x.append(sentence[i:i + NGRAM_SIZE - 1])\n",
    "        training_y.append(sentence[i + NGRAM_SIZE - 1])\n",
    "\n",
    "    return (training_x, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKODP3ZKlxU3",
    "outputId": "fff2349c-dd5f-44c6-c36b-733cf0934ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 3], [1, 1, 1, 1, 3, 1444], [1, 1, 1, 3, 1444, 3133], [1, 1, 3, 1444, 3133, 4]]\n",
      "(276808, 6)\n",
      "[3, 1444, 3133, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "training_x, training_y = generate_ngram_training_samples(encoded)\n",
    "\n",
    "print(training_x[0:5])\n",
    "print(np.shape(training_x))\n",
    "print(training_y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DvYp32sTnqeu"
   },
   "outputs": [],
   "source": [
    "def create_word_to_embedding(embs: KeyedVectors) -> dict:\n",
    "    \"\"\"\n",
    "    Creates a mapping from each word in the embedding vocabulary to its embedding.\n",
    "    \"\"\"\n",
    "    word_to_embedding = {}\n",
    "    for word in embs.key_to_index.keys():\n",
    "      word_to_embedding[word] = embs[word]\n",
    "    return word_to_embedding\n",
    "\n",
    "def create_index_to_embedding(embs: KeyedVectors, tokenizer: Tokenizer) -> dict:\n",
    "  \"\"\"\n",
    "  Creates a mapping from the tokenizer index of each word in the embedding vocabulary to its embedding.\n",
    "  \"\"\"\n",
    "  index_to_embedding = {}\n",
    "  for word in embs.key_to_index.keys():\n",
    "    index = tokenizer.word_index[word]\n",
    "    index_to_embedding[index] = embs[word]\n",
    "  return index_to_embedding\n",
    "\n",
    "def get_word_to_index(word: str, tokenizer: Tokenizer):\n",
    "  return tokenizer.texts_to_sequences([[word]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ER9c6GYEpCLv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14269\n"
     ]
    }
   ],
   "source": [
    "word_to_embedding = create_word_to_embedding(reddit_haiku_embs)\n",
    "index_to_embedding = create_index_to_embedding(reddit_haiku_embs, tokenizer)\n",
    "print(len(index_to_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eULBI9fiuJKJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsample = next(data_generator(rnn_training_x, rnn_training_y, 2, index_to_embedding))\\nsample = next(data_generator(training_x, training_y, 33, index_to_embedding))\\nprint(sample)\\nprint(np.shape(sample[0])) # batch_size, emb_size * n-1 -- (concatenated embeddings of n-1-word sample)\\nprint(np.shape(sample[1])) # batch_size, len(index_to_embedding) -- (a one-hot vector for each nth word result)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_generator(X: list, y: list, num_sequences_per_batch: int, i_to_emb: dict):\n",
    "    '''\n",
    "    Returns data generator to be used by feed_forward\n",
    "    https://wiki.python.org/moin/Generators\n",
    "    https://realpython.com/introduction-to-python-generators/\n",
    "    \n",
    "    Yields batches of embeddings and labels to go with them.\n",
    "    Use one hot vectors to encode the labels \n",
    "    (see the to_categorical function)\n",
    "\n",
    "    Requires a mapping to convert from tokenizer index to embedding vector.\n",
    "    \n",
    "    '''  \n",
    "    embs = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        i = i % len(X)\n",
    "        \n",
    "        emb = [i_to_emb[n] for n in X[i]]  # [ [..200..], [..200..] ] list of lists, shape (n-1, embedding_size)\n",
    "        embs.append(emb)  # list of list of lists, shape (batch_size, n-1, emb_size)\n",
    "        # we want shape (batch_size, (n-1)*emb_size)\n",
    "\n",
    "        # create one-hot vector with the 1 at the location of the tokenizer index\n",
    "        # adding 1 to length to account for vector indices starting from 1 instead of 0\n",
    "        label = to_categorical(y[i], num_classes=len(i_to_emb)+1)\n",
    "        labels.append(label)\n",
    "        if len(embs) % num_sequences_per_batch == 0:\n",
    "            yield (np.reshape(embs, (num_sequences_per_batch, -1)), np.array(labels))\n",
    "            embs = []\n",
    "            labels = []\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    "sample = next(data_generator(rnn_training_x, rnn_training_y, 2, index_to_embedding))\n",
    "sample = next(data_generator(training_x, training_y, 33, index_to_embedding))\n",
    "print(sample)\n",
    "print(np.shape(sample[0])) # batch_size, emb_size * n-1 -- (concatenated embeddings of n-1-word sample)\n",
    "print(np.shape(sample[1])) # batch_size, len(index_to_embedding) -- (a one-hot vector for each nth word result)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sE8nhQE1uify"
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(training_x, training_y, BATCH_SIZE, index_to_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYDertZoVLNS"
   },
   "source": [
    "# Model 1: feedforward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BEs06_vsVUeb"
   },
   "outputs": [],
   "source": [
    "def build_feed_forward_model(input_units, hidden_units, output_units):\n",
    "  model = Sequential()\n",
    "  \n",
    "  model.add(Input(shape=(input_units,)))  # inputs will be vectors of this length, batch size not specified\n",
    "  model.add(Dense(hidden_units, activation=\"softmax\"))\n",
    "  model.add(Dense(output_units, activation=\"softmax\"))\n",
    "  \n",
    "  model.compile(optimizer=Adam(learning_rate=0.01), loss=CategoricalCrossentropy())\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hGdyYdHkVU-g"
   },
   "outputs": [],
   "source": [
    "output_units = len(reddit_haiku_embs.key_to_index.keys()) + 1\n",
    "hidden_units = 1000 #round((INPUT_UNITS + output_units) / 2)\n",
    "\n",
    "feed_forward_model = build_feed_forward_model(INPUT_UNITS, hidden_units, output_units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed_forward_model.fit(x=train_generator, epochs=EPOCHS, steps_per_epoch=len(training_x) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed_forward_model.save(\"ffnn_model_trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyHEqmRFVSUt"
   },
   "source": [
    "# Model 2: RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm produces 1 label per timestep, so timestep = n-1-gram \n",
    "# timestep size = NGRAM_SIZE - 1 (4)\n",
    "# timestep consists of n-1 word embeddings, each with some features\n",
    "# features = EMBEDDING_SIZE (200)\n",
    "# then we can do this for a certain number of batches, lets say 128 still\n",
    "# the inputs to the LSTM need to have shape (batch_size, timesteps, features)\n",
    "# so for us that means shape (BATCH_SIZE, NGRAM_SIZE-1, EMBEDDING_SIZE)\n",
    "\n",
    "# upshot: have to make a new data generator, sicne the FFNN one squished all the embeddings together\n",
    "\n",
    "# timestep = ngram length is supported by several example articles: \n",
    "# http://ethen8181.github.io/machine-learning/keras/rnn_language_model_basic_keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 6, 200)\n",
      "(128, 14270)\n"
     ]
    }
   ],
   "source": [
    "def rnn_data_generator(X: list, y: list, batch_size: int, i_to_emb: dict):\n",
    "    '''\n",
    "    Produces a data generator for an RNN.\n",
    "    Output data is of shape (batch_size, len(X[0]), len(i_to_emb.values()[1])\n",
    "    i.e. (batch_size, ngram_size - 1, embedding_size)\n",
    "    Output labels are one-hot vectors of shape (batch_size, len(i_to_emb.keys())+1)\n",
    "    i.e. (batch_size, vocab_size) \n",
    "    '''  \n",
    "    embs = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        i = i % len(X)\n",
    "        \n",
    "        emb = [i_to_emb[n] for n in X[i]]  # [ [..200..], [..200..] ] list of lists, shape (n-1, embedding_size)\n",
    "        embs.append(emb)  # list of list of lists, shape (batch_size, n-1, emb_size)\n",
    "\n",
    "        # create one-hot vector with the 1 at the location of the tokenizer index\n",
    "        # adding 1 to length to account for vector indices starting from 1 instead of 0\n",
    "        label = to_categorical(y[i], num_classes=len(i_to_emb)+1)\n",
    "        labels.append(label)\n",
    "        if len(embs) % batch_size == 0:\n",
    "            #yield (np.array(embs), np.reshape(labels, (batch_size, len(i_to_emb)+1, 1)))\n",
    "            yield (np.array(embs), np.array(labels))\n",
    "            embs = []\n",
    "            labels = []\n",
    "\n",
    "        i += 1\n",
    "\n",
    "rnn_training_generator = rnn_data_generator(training_x, training_y, BATCH_SIZE, index_to_embedding)\n",
    "sample = next(rnn_training_generator)\n",
    "print(np.shape(sample[0]))\n",
    "print(np.shape(sample[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_model(timestep_size, input_units, hidden_units, output_units):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # input size needs to be a tuple of (timesteps, features), \n",
    "    # per https://towardsdatascience.com/a-practical-guide-to-rnn-and-lstm-in-keras-980f176271bc\n",
    "    model.add(Input(shape=(timestep_size, input_units)))  # (4, 200)\n",
    "    model.add(LSTM(hidden_units))\n",
    "    model.add(Dense(output_units, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss=CategoricalCrossentropy())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               168448    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 14270)             1840830   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,009,278\n",
      "Trainable params: 2,009,278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "hidden_units = 128 # a lot of the examples used 128\n",
    "output_units = len(reddit_haiku_embs.key_to_index.keys()) + 1\n",
    "\n",
    "rnn_model = build_rnn_model(NGRAM_SIZE - 1, EMBEDDING_SIZE, hidden_units, output_units)\n",
    "print(rnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2162/2162 [==============================] - 783s 359ms/step - loss: 3.8615\n",
      "Epoch 2/3\n",
      "2162/2162 [==============================] - 771s 357ms/step - loss: 3.4208\n",
      "Epoch 3/3\n",
      "2162/2162 [==============================] - 772s 357ms/step - loss: 3.2394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19ca1d5c9d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model_large = build_rnn_model(NGRAM_SIZE - 1, EMBEDDING_SIZE, 500, output_units)\n",
    "rnn_model_large.fit(x=rnn_training_generator, epochs=EPOCHS, steps_per_epoch=len(training_x) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = rnn_model(next(rnn_training_generator)[0])\n",
    "#print(y)  # output of model is (batch_size, vocab_size), i.e. a one-hot vector for each timestep\n",
    "#print(rnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2162/2162 [==============================] - 275s 124ms/step - loss: 3.9251\n",
      "Epoch 2/3\n",
      "2162/2162 [==============================] - 272s 126ms/step - loss: 3.5058\n",
      "Epoch 3/3\n",
      "2162/2162 [==============================] - 272s 126ms/step - loss: 3.3409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19ccf541130>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.fit(x=rnn_training_generator, epochs=EPOCHS, steps_per_epoch=len(training_x) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn_model.save(\"rnn_model_n_5\")  # NGRAM_SIZE = 5, 128 hidden units\n",
    "#rnn_model.save(\"rnn_model_trained\")  # NGRAM_SIZE = 7, 128 hidden units\n",
    "#rnn_model.save(\"rnn_model_large_trained\") # NGRAM_SIZE = 7, 500 hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Haikus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved models\n",
    "feed_forward_model = load_model(\"ffnn_model_trained\")\n",
    "#rnn_model_small = load_model(\"rnn_model_trained\")\n",
    "rnn_model_small = rnn_model\n",
    "#rnn_model_large = load_model(\"rnn_model_large_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data_generator(X: list, num_sequences_per_batch: int, i_to_emb: dict, is_rnn=False) -> list:\n",
    "    '''\n",
    "    Returns data generator to be used for prediction data\n",
    "    \n",
    "    Yields batches of embeddings to go with them.\n",
    "    Use one hot vectors to encode the labels \n",
    "    (see the to_categorical function)\n",
    "\n",
    "    Requires a mapping to convert from tokenizer index to embedding vector.\n",
    "    \n",
    "    '''  \n",
    "    embs = []\n",
    "    for i in range(len(X)):\n",
    "        emb = [i_to_emb[n] for n in X[i]]  # [ [..200..], [..200..] ] list of lists, shape (n-1, embedding_size)\n",
    "        embs.append(emb)  # list of list of lists, shape (batch_size, n-1, emb_size)\n",
    "        # we want shape (batch_size, (n-1)*emb_size)\n",
    "\n",
    "        # create one-hot vector with the 1 at the location of the tokenizer index\n",
    "        if len(embs) % num_sequences_per_batch == 0:\n",
    "            if is_rnn:\n",
    "                yield np.array(embs)\n",
    "            else:\n",
    "                yield np.reshape(embs, (num_sequences_per_batch, -1))\n",
    "            embs = []\n",
    "\n",
    "\n",
    "def generate_haiku(model: Sequential, \n",
    "                 tokenizer: Tokenizer, \n",
    "                 seed: list,\n",
    "                 i_to_emb: dict,\n",
    "                 n_words: int,\n",
    "                  is_rnn=False):\n",
    "    '''\n",
    "    Generate a haiku from the given model\n",
    "    \n",
    "    Parameters:\n",
    "        model: your neural network\n",
    "        tokenizer: the keras preprocessing tokenizer\n",
    "        seed: [w1, w2, w(n-1)]\n",
    "        n_words: generate a sentence of length n_words\n",
    "    Returns: string sentence\n",
    "    '''\n",
    "    sentence = seed\n",
    "    sentence_indices = tokenizer.texts_to_sequences([seed])[0]\n",
    "\n",
    "    # make the input list for the model.predict\n",
    "    # format is the n_grams so [[1, 2], [2, 3], [3, 4] ...]\n",
    "    predict_input = []\n",
    "    for i in range(len(sentence_indices) - NGRAM_SIZE + 2):\n",
    "        predict_input += [sentence_indices[i:i + NGRAM_SIZE]]\n",
    "    \n",
    "    \n",
    "    n_words_generated = 0\n",
    "    while n_words_generated < n_words:\n",
    "        #print(\"predict input: \", predict_input)\n",
    "        if is_rnn:\n",
    "            gen = predict_data_generator(predict_input, len(predict_input), i_to_emb, is_rnn=True)\n",
    "        else:\n",
    "            gen = predict_data_generator(predict_input, len(predict_input), i_to_emb)\n",
    "        \n",
    "        probabilities = model.predict(x=gen, verbose=None)[0]\n",
    "\n",
    "        all_word_counts = [i for i in range(len(i_to_emb.keys()) + 1)]\n",
    "        sampled_index = np.random.choice(all_word_counts, p=probabilities)\n",
    "        new_word = tokenizer.sequences_to_texts([[sampled_index]])[0]\n",
    "      \n",
    "        sentence.append(new_word)\n",
    "        sentence_indices.append(sampled_index)\n",
    "        predict_input.append(sentence_indices[-(NGRAM_SIZE - 1):])\n",
    "        predict_input = predict_input[1:]\n",
    "      \n",
    "        if sentence[-1] == HAIKU_END:\n",
    "            break\n",
    "      \n",
    "        n_words_generated += 1\n",
    "    \n",
    "\n",
    "    return \" \".join(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syllables(sentence: list, syllable_dictionary: dict):\n",
    "    '''\n",
    "    Counts the number of syllables in the given sentence.\n",
    "    Unseen tokens return an error value of None, ensuring that the model cannot greedily end a line too early.\n",
    "    '''\n",
    "    \n",
    "    count = 0\n",
    "    for word in sentence:\n",
    "        if syllable_dictionary.get(word) is None:\n",
    "            return None\n",
    "        else:\n",
    "            count += syllable_dictionary.get(word)\n",
    "    \n",
    "    return count\n",
    "\n",
    "def generate_haiku_greedy(model: Sequential, tokenizer: Tokenizer, i_to_emb: dict, syllable_dict: dict, seed=None, is_rnn=False):\n",
    "    '''\n",
    "    Generates a haiku from the model, ensuring a syllable fit using a greedy algorithm.\n",
    "    \n",
    "    Seed (optional) should be a list of tokens of length NGRAM_SIZE - 1 for the model to predict from.\n",
    "    If not specified, NGRAM_SIZE-1 haiku begin tokens will be used.\n",
    "    '''\n",
    "    if seed is None:\n",
    "        haiku = [HAIKU_BEGIN] * (NGRAM_SIZE - 1)\n",
    "    else:\n",
    "        haiku = seed\n",
    "    \n",
    "    haiku.append(LINE_BEGIN)\n",
    "    haiku_indices = tokenizer.texts_to_sequences([haiku])[0]\n",
    "\n",
    "    \n",
    "    line_number = 1\n",
    "    line = []\n",
    "    \n",
    "    while True:\n",
    "        # get the ngram window to generate the next word\n",
    "        window_indices = haiku_indices[-(NGRAM_SIZE - 1):]\n",
    "        # convert to embeddings\n",
    "        window_embs = np.reshape([i_to_emb[i] for i in window_indices], (1, NGRAM_SIZE - 1, -1))\n",
    "        if not is_rnn:\n",
    "            window_embs = np.reshape(window_embs, (1, -1))\n",
    "        \n",
    "        probabilities = model.predict(x=window_embs, verbose=None)[0]\n",
    "        \n",
    "        \n",
    "        all_word_indices = [i for i in range(len(i_to_emb.keys()) + 1)]\n",
    "        sampled_index = np.random.choice(all_word_indices, p=probabilities)\n",
    "        new_word = tokenizer.sequences_to_texts([[sampled_index]])[0]\n",
    "        \n",
    "        line_syllables = get_syllables(line, syllable_dict)\n",
    "        \n",
    "        # if the one we got doesn't fit/can't be found, sample w/o replacement until one does fit\n",
    "        while (get_syllables([new_word], syllable_dict) is None \n",
    "               or get_syllables([new_word], syllable_dict) > line_structure[line_number] - line_syllables):\n",
    "            sampled_index = np.random.choice(all_word_indices, p=probabilities, replace=False)\n",
    "            new_word = tokenizer.sequences_to_texts([[sampled_index]])[0]\n",
    "        \n",
    "        if line_syllables + get_syllables([new_word], syllable_dict) == line_structure[line_number]:\n",
    "            haiku.append(new_word)\n",
    "            haiku.append(LINE_END)\n",
    "            haiku_indices.append(sampled_index)\n",
    "            haiku_indices.append(get_word_to_index(LINE_END, tokenizer))  # end the current line\n",
    "            \n",
    "            if line_number == 3:  # end the poem\n",
    "                haiku.extend([HAIKU_END] * (NGRAM_SIZE-1))\n",
    "                return ' '.join(haiku)\n",
    "            else:  \n",
    "                haiku.append(LINE_BEGIN)  # start a new line\n",
    "                haiku_indices.append(get_word_to_index(LINE_BEGIN, tokenizer))\n",
    "                line_number += 1\n",
    "                line = []\n",
    "        \n",
    "        elif line_syllables + get_syllables([new_word], syllable_dict) < line_structure[line_number]:\n",
    "            haiku.append(new_word)\n",
    "            haiku_indices.append(sampled_index)\n",
    "            line.append(new_word)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_haiku(haiku: str):\n",
    "    haiku = haiku.replace(\"<h> \", \"\")\n",
    "    haiku = haiku.replace(\"</h> \", \"\")\n",
    "    haiku = haiku.replace(\"<s> \", \"\")\n",
    "    haiku = haiku.replace(\"<s>\", \"\\n\")\n",
    "    print(haiku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h> <h> <h> <h> <h> <h> </s> <s> i </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> longing stress cannot </s> </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> goodbye time their his mist cavern reason on by truth no </s> fat </s> heretodayreally so snow </s> bow be the </s> assist we </h>\n",
      "<h> <h> <h> <h> <h> <h> would i black beautiful heads </s> you teach seek starts on i were drown crave </s> rime <s> </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> in <s> the </s> free wings mounds eat beat i've weather woman world </s> within flora </s> <s> and sometimes not can by desires <s> </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> strangers throttle icarus turns the </s> progress than </s> <s> animals </s> <s> </s> </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> at september box </s> presence pulls </s> a petrol my the will with <s> <s> </s> <s> much over sense weighs bad </s> <s> my up chilly but pain </s>\n",
      "<h> <h> <h> <h> <h> <h> i back </s> <s> while wrapped </s> of </h>\n",
      "<h> <h> <h> <h> <h> <h> i have </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> hurts a count simple is </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> night </s> one on equals metal spread to old me astral shivers </s> </s> <s> the try night </s> see go </s> <s> no </s> defiant haikus crawling you piece\n",
      "<h> <h> <h> <h> <h> <h> friend bath </s> reigned a </s> <s> </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> me </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> to cicadas suffering events growing i how quiet the open the open memory white breathes steam </s> i books through war </s> <s> looking while the are </h>\n",
      "<h> <h> <h> <h> <h> <h> i robbed lunch the </s> illuminated slippery that goal the rain </s> </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> when mares' mighty </s> die out she are <s> </s> to out </s> weak eyes homeless </s> deserve </s> <s> branch i village rain to </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> everything love song for </h>\n",
      "<h> <h> <h> <h> <h> <h> head starts </s> what where get healing wheel like into a waves 'pinch i be what paint teapots at </s> </h>\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    ffnn_haiku = generate_haiku(feed_forward_model, tokenizer, [HAIKU_BEGIN] * (NGRAM_SIZE - 1), index_to_embedding, 30)\n",
    "    print(ffnn_haiku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 295]]\n",
      "predict input:  [[1, 1, 1, 3, 295, 3564]]\n",
      "predict input:  [[1, 1, 3, 295, 3564, 237]]\n",
      "predict input:  [[1, 3, 295, 3564, 237, 4]]\n",
      "predict input:  [[3, 295, 3564, 237, 4, 3]]\n",
      "predict input:  [[295, 3564, 237, 4, 3, 3850]]\n",
      "predict input:  [[3564, 237, 4, 3, 3850, 3101]]\n",
      "predict input:  [[237, 4, 3, 3850, 3101, 3101]]\n",
      "predict input:  [[4, 3, 3850, 3101, 3101, 1274]]\n",
      "predict input:  [[3, 3850, 3101, 3101, 1274, 3101]]\n",
      "predict input:  [[3850, 3101, 3101, 1274, 3101, 1274]]\n",
      "predict input:  [[3101, 3101, 1274, 3101, 1274, 2389]]\n",
      "predict input:  [[3101, 1274, 3101, 1274, 2389, 4]]\n",
      "predict input:  [[1274, 3101, 1274, 2389, 4, 3]]\n",
      "predict input:  [[3101, 1274, 2389, 4, 3, 13]]\n",
      "predict input:  [[1274, 2389, 4, 3, 13, 723]]\n",
      "predict input:  [[2389, 4, 3, 13, 723, 38]]\n",
      "predict input:  [[4, 3, 13, 723, 38, 5]]\n",
      "predict input:  [[3, 13, 723, 38, 5, 1163]]\n",
      "predict input:  [[13, 723, 38, 5, 1163, 823]]\n",
      "predict input:  [[723, 38, 5, 1163, 823, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> forever beginnings dead </s> <s> gucci m m huh m huh traveling </s> <s> and tongue by the wood weather </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 8]]\n",
      "predict input:  [[1, 1, 1, 3, 8, 683]]\n",
      "predict input:  [[1, 1, 3, 8, 683, 37]]\n",
      "predict input:  [[1, 3, 8, 683, 37, 54]]\n",
      "predict input:  [[3, 8, 683, 37, 54, 21]]\n",
      "predict input:  [[8, 683, 37, 54, 21, 4]]\n",
      "predict input:  [[683, 37, 54, 21, 4, 3]]\n",
      "predict input:  [[37, 54, 21, 4, 3, 29]]\n",
      "predict input:  [[54, 21, 4, 3, 29, 14]]\n",
      "predict input:  [[21, 4, 3, 29, 14, 9]]\n",
      "predict input:  [[4, 3, 29, 14, 9, 760]]\n",
      "predict input:  [[3, 29, 14, 9, 760, 4]]\n",
      "predict input:  [[29, 14, 9, 760, 4, 3]]\n",
      "predict input:  [[14, 9, 760, 4, 3, 13]]\n",
      "predict input:  [[9, 760, 4, 3, 13, 722]]\n",
      "predict input:  [[760, 4, 3, 13, 722, 215]]\n",
      "predict input:  [[4, 3, 13, 722, 215, 49]]\n",
      "predict input:  [[3, 13, 722, 215, 49, 161]]\n",
      "predict input:  [[13, 722, 215, 49, 161, 4]]\n",
      "predict input:  [[722, 215, 49, 161, 4, 3]]\n",
      "predict input:  [[215, 49, 161, 4, 3, 1931]]\n",
      "predict input:  [[49, 161, 4, 3, 1931, 580]]\n",
      "predict input:  [[161, 4, 3, 1931, 580, 80]]\n",
      "predict input:  [[4, 3, 1931, 580, 80, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> to speak life when love </s> <s> that is my book </s> <s> and nose peace out off </s> <s> sweetly finally again </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 11855]]\n",
      "predict input:  [[1, 1, 1, 3, 11855, 625]]\n",
      "predict input:  [[1, 1, 3, 11855, 625, 4]]\n",
      "predict input:  [[1, 3, 11855, 625, 4, 3]]\n",
      "predict input:  [[3, 11855, 625, 4, 3, 5]]\n",
      "predict input:  [[11855, 625, 4, 3, 5, 76]]\n",
      "predict input:  [[625, 4, 3, 5, 76, 1705]]\n",
      "predict input:  [[4, 3, 5, 76, 1705, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> wrapping sounds </s> <s> the more therapy </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 460]]\n",
      "predict input:  [[1, 1, 1, 3, 460, 1176]]\n",
      "predict input:  [[1, 1, 3, 460, 1176, 119]]\n",
      "predict input:  [[1, 3, 460, 1176, 119, 85]]\n",
      "predict input:  [[3, 460, 1176, 119, 85, 4]]\n",
      "predict input:  [[460, 1176, 119, 85, 4, 3]]\n",
      "predict input:  [[1176, 119, 85, 4, 3, 1229]]\n",
      "predict input:  [[119, 85, 4, 3, 1229, 336]]\n",
      "predict input:  [[85, 4, 3, 1229, 336, 288]]\n",
      "predict input:  [[4, 3, 1229, 336, 288, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> sitting edge summer leaves </s> <s> somebody bad something </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 2807]]\n",
      "predict input:  [[1, 1, 1, 3, 2807, 1776]]\n",
      "predict input:  [[1, 1, 3, 2807, 1776, 4]]\n",
      "predict input:  [[1, 3, 2807, 1776, 4, 3]]\n",
      "predict input:  [[3, 2807, 1776, 4, 3, 919]]\n",
      "predict input:  [[2807, 1776, 4, 3, 919, 14156]]\n",
      "predict input:  [[1776, 4, 3, 919, 14156, 38]]\n",
      "predict input:  [[4, 3, 919, 14156, 38, 5]]\n",
      "predict input:  [[3, 919, 14156, 38, 5, 39]]\n",
      "predict input:  [[919, 14156, 38, 5, 39, 4]]\n",
      "predict input:  [[14156, 38, 5, 39, 4, 3]]\n",
      "predict input:  [[38, 5, 39, 4, 3, 204]]\n",
      "predict input:  [[5, 39, 4, 3, 204, 3200]]\n",
      "predict input:  [[39, 4, 3, 204, 3200, 1561]]\n",
      "predict input:  [[4, 3, 204, 3200, 1561, 313]]\n",
      "predict input:  [[3, 204, 3200, 1561, 313, 4]]\n",
      "predict input:  [[204, 3200, 1561, 313, 4, 3]]\n",
      "predict input:  [[3200, 1561, 313, 4, 3, 1566]]\n",
      "predict input:  [[1561, 313, 4, 3, 1566, 1301]]\n",
      "predict input:  [[313, 4, 3, 1566, 1301, 33]]\n",
      "predict input:  [[4, 3, 1566, 1301, 33, 11]]\n",
      "predict input:  [[3, 1566, 1301, 33, 11, 54]]\n",
      "predict input:  [[1566, 1301, 33, 11, 54, 4]]\n",
      "predict input:  [[1301, 33, 11, 54, 4, 3]]\n",
      "predict input:  [[33, 11, 54, 4, 3, 10]]\n",
      "predict input:  [[11, 54, 4, 3, 10, 5]]\n",
      "predict input:  [[54, 4, 3, 10, 5, 345]]\n",
      "predict input:  [[4, 3, 10, 5, 345, 1779]]\n",
      "<h> <h> <h> <h> <h> <h> <s> streaks willow </s> <s> faces incoming by the time </s> <s> empty stain spread outside </s> <s> tracks none will you when </s> <s> in the most awakens light\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 3092]]\n",
      "predict input:  [[1, 1, 1, 3, 3092, 18]]\n",
      "predict input:  [[1, 1, 3, 3092, 18, 608]]\n",
      "predict input:  [[1, 3, 3092, 18, 608, 4]]\n",
      "predict input:  [[3, 3092, 18, 608, 4, 3]]\n",
      "predict input:  [[3092, 18, 608, 4, 3, 54]]\n",
      "predict input:  [[18, 608, 4, 3, 54, 25]]\n",
      "predict input:  [[608, 4, 3, 54, 25, 1771]]\n",
      "predict input:  [[4, 3, 54, 25, 1771, 13]]\n",
      "predict input:  [[3, 54, 25, 1771, 13, 72]]\n",
      "predict input:  [[54, 25, 1771, 13, 72, 74]]\n",
      "predict input:  [[25, 1771, 13, 72, 74, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> youtube on yours </s> <s> when we simply and too haiku </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 37]]\n",
      "predict input:  [[1, 1, 1, 3, 37, 14]]\n",
      "predict input:  [[1, 1, 3, 37, 14, 5]]\n",
      "predict input:  [[1, 3, 37, 14, 5, 409]]\n",
      "predict input:  [[3, 37, 14, 5, 409, 4]]\n",
      "predict input:  [[37, 14, 5, 409, 4, 3]]\n",
      "predict input:  [[14, 5, 409, 4, 3, 34]]\n",
      "predict input:  [[5, 409, 4, 3, 34, 507]]\n",
      "predict input:  [[409, 4, 3, 34, 507, 33]]\n",
      "predict input:  [[4, 3, 34, 507, 33, 2651]]\n",
      "predict input:  [[3, 34, 507, 33, 2651, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> life is the future </s> <s> now mother will flee </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 822]]\n",
      "predict input:  [[1, 1, 1, 3, 822, 111]]\n",
      "predict input:  [[1, 1, 3, 822, 111, 111]]\n",
      "predict input:  [[1, 3, 822, 111, 111, 218]]\n",
      "predict input:  [[3, 822, 111, 111, 218, 17]]\n",
      "predict input:  [[822, 111, 111, 218, 17, 558]]\n",
      "predict input:  [[111, 111, 218, 17, 558, 15]]\n",
      "predict input:  [[111, 218, 17, 558, 15, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> what's who who said it gave me </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 9]]\n",
      "predict input:  [[1, 1, 1, 3, 9, 133]]\n",
      "predict input:  [[1, 1, 3, 9, 133, 14]]\n",
      "predict input:  [[1, 3, 9, 133, 14, 491]]\n",
      "predict input:  [[3, 9, 133, 14, 491, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> my thoughts is cut </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 6]]\n",
      "predict input:  [[1, 1, 1, 3, 6, 78]]\n",
      "predict input:  [[1, 1, 3, 6, 78, 6]]\n",
      "predict input:  [[1, 3, 6, 78, 6, 43]]\n",
      "predict input:  [[3, 6, 78, 6, 43, 268]]\n",
      "predict input:  [[6, 78, 6, 43, 268, 36]]\n",
      "predict input:  [[78, 6, 43, 268, 36, 29]]\n",
      "predict input:  [[6, 43, 268, 36, 29, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> i don't i have better from that </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 411]]\n",
      "predict input:  [[1, 1, 1, 3, 411, 26]]\n",
      "predict input:  [[1, 1, 3, 411, 26, 2019]]\n",
      "predict input:  [[1, 3, 411, 26, 2019, 4]]\n",
      "predict input:  [[3, 411, 26, 2019, 4, 3]]\n",
      "predict input:  [[411, 26, 2019, 4, 3, 366]]\n",
      "predict input:  [[26, 2019, 4, 3, 366, 280]]\n",
      "predict input:  [[2019, 4, 3, 366, 280, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> eat this crazy </s> <s> took perfect </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict input:  [[1, 1, 1, 1, 3, 41]]\n",
      "predict input:  [[1, 1, 1, 3, 41, 303]]\n",
      "predict input:  [[1, 1, 3, 41, 303, 73]]\n",
      "predict input:  [[1, 3, 41, 303, 73, 4]]\n",
      "predict input:  [[3, 41, 303, 73, 4, 3]]\n",
      "predict input:  [[41, 303, 73, 4, 3, 1263]]\n",
      "predict input:  [[303, 73, 4, 3, 1263, 51]]\n",
      "predict input:  [[73, 4, 3, 1263, 51, 1387]]\n",
      "predict input:  [[4, 3, 1263, 51, 1387, 4]]\n",
      "predict input:  [[3, 1263, 51, 1387, 4, 3]]\n",
      "predict input:  [[1263, 51, 1387, 4, 3, 13621]]\n",
      "predict input:  [[51, 1387, 4, 3, 13621, 1476]]\n",
      "predict input:  [[1387, 4, 3, 13621, 1476, 4936]]\n",
      "predict input:  [[4, 3, 13621, 1476, 4936, 799]]\n",
      "predict input:  [[3, 13621, 1476, 4936, 799, 4]]\n",
      "predict input:  [[13621, 1476, 4936, 799, 4, 3]]\n",
      "predict input:  [[1476, 4936, 799, 4, 3, 186]]\n",
      "predict input:  [[4936, 799, 4, 3, 186, 9]]\n",
      "predict input:  [[799, 4, 3, 186, 9, 14110]]\n",
      "predict input:  [[4, 3, 186, 9, 14110, 25]]\n",
      "predict input:  [[3, 186, 9, 14110, 25, 4]]\n",
      "predict input:  [[186, 9, 14110, 25, 4, 3]]\n",
      "predict input:  [[9, 14110, 25, 4, 3, 916]]\n",
      "predict input:  [[14110, 25, 4, 3, 916, 4421]]\n",
      "predict input:  [[25, 4, 3, 916, 4421, 3034]]\n",
      "predict input:  [[4, 3, 916, 4421, 3034, 37]]\n",
      "predict input:  [[3, 916, 4421, 3034, 37, 4]]\n",
      "predict input:  [[916, 4421, 3034, 37, 4, 3]]\n",
      "<h> <h> <h> <h> <h> <h> <s> as cool sky </s> <s> anxious was kept </s> <s> billows adrift mice dreaming </s> <s> while my circumstances we </s> <s> mask fabric gut life </s> <s> mist\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 740]]\n",
      "predict input:  [[1, 1, 1, 3, 740, 10]]\n",
      "predict input:  [[1, 1, 3, 740, 10, 1414]]\n",
      "predict input:  [[1, 3, 740, 10, 1414, 4]]\n",
      "predict input:  [[3, 740, 10, 1414, 4, 3]]\n",
      "predict input:  [[740, 10, 1414, 4, 3, 586]]\n",
      "predict input:  [[10, 1414, 4, 3, 586, 168]]\n",
      "predict input:  [[1414, 4, 3, 586, 168, 12]]\n",
      "predict input:  [[4, 3, 586, 168, 12, 2160]]\n",
      "predict input:  [[3, 586, 168, 12, 2160, 4]]\n",
      "predict input:  [[586, 168, 12, 2160, 4, 3]]\n",
      "predict input:  [[168, 12, 2160, 4, 3, 482]]\n",
      "predict input:  [[12, 2160, 4, 3, 482, 12]]\n",
      "predict input:  [[2160, 4, 3, 482, 12, 11]]\n",
      "predict input:  [[4, 3, 482, 12, 11, 4]]\n",
      "predict input:  [[3, 482, 12, 11, 4, 3]]\n",
      "predict input:  [[482, 12, 11, 4, 3, 743]]\n",
      "predict input:  [[12, 11, 4, 3, 743, 1236]]\n",
      "predict input:  [[11, 4, 3, 743, 1236, 91]]\n",
      "predict input:  [[4, 3, 743, 1236, 91, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> fade in mud </s> <s> seen gone of nectar </s> <s> hearts of you </s> <s> brought somehow go </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 613]]\n",
      "predict input:  [[1, 1, 1, 3, 613, 181]]\n",
      "predict input:  [[1, 1, 3, 613, 181, 16]]\n",
      "predict input:  [[1, 3, 613, 181, 16, 1612]]\n",
      "predict input:  [[3, 613, 181, 16, 1612, 4]]\n",
      "predict input:  [[613, 181, 16, 1612, 4, 3]]\n",
      "predict input:  [[181, 16, 1612, 4, 3, 4354]]\n",
      "predict input:  [[16, 1612, 4, 3, 4354, 4419]]\n",
      "predict input:  [[1612, 4, 3, 4354, 4419, 14199]]\n",
      "predict input:  [[4, 3, 4354, 4419, 14199, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> sunset hard for nighttime </s> <s> boiling expand fables </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 126]]\n",
      "predict input:  [[1, 1, 1, 3, 126, 1222]]\n",
      "predict input:  [[1, 1, 3, 126, 1222, 11]]\n",
      "predict input:  [[1, 3, 126, 1222, 11, 54]]\n",
      "predict input:  [[3, 126, 1222, 11, 54, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> please check you when </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 2682]]\n",
      "predict input:  [[1, 1, 1, 3, 2682, 12]]\n",
      "predict input:  [[1, 1, 3, 2682, 12, 1643]]\n",
      "predict input:  [[1, 3, 2682, 12, 1643, 2468]]\n",
      "predict input:  [[3, 2682, 12, 1643, 2468, 4]]\n",
      "predict input:  [[2682, 12, 1643, 2468, 4, 3]]\n",
      "predict input:  [[12, 1643, 2468, 4, 3, 13]]\n",
      "predict input:  [[1643, 2468, 4, 3, 13, 17]]\n",
      "predict input:  [[2468, 4, 3, 13, 17, 53]]\n",
      "predict input:  [[4, 3, 13, 17, 53, 621]]\n",
      "predict input:  [[3, 13, 17, 53, 621, 874]]\n",
      "predict input:  [[13, 17, 53, 621, 874, 4]]\n",
      "predict input:  [[17, 53, 621, 874, 4, 3]]\n",
      "predict input:  [[53, 621, 874, 4, 3, 90]]\n",
      "predict input:  [[621, 874, 4, 3, 90, 29]]\n",
      "predict input:  [[874, 4, 3, 90, 29, 3381]]\n",
      "predict input:  [[4, 3, 90, 29, 3381, 17]]\n",
      "predict input:  [[3, 90, 29, 3381, 17, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> themselves of worst pancakes </s> <s> and it can use march </s> <s> if that starve it </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 158]]\n",
      "predict input:  [[1, 1, 1, 3, 158, 93]]\n",
      "predict input:  [[1, 1, 3, 158, 93, 9]]\n",
      "predict input:  [[1, 3, 158, 93, 9, 213]]\n",
      "predict input:  [[3, 158, 93, 9, 213, 4]]\n",
      "predict input:  [[158, 93, 9, 213, 4, 3]]\n",
      "predict input:  [[93, 9, 213, 4, 3, 495]]\n",
      "predict input:  [[9, 213, 4, 3, 495, 26]]\n",
      "predict input:  [[213, 4, 3, 495, 26, 362]]\n",
      "predict input:  [[4, 3, 495, 26, 362, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> first into my green </s> <s> turns this body </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 4708]]\n",
      "predict input:  [[1, 1, 1, 3, 4708, 156]]\n",
      "predict input:  [[1, 1, 3, 4708, 156, 161]]\n",
      "predict input:  [[1, 3, 4708, 156, 161, 4]]\n",
      "predict input:  [[3, 4708, 156, 161, 4, 3]]\n",
      "predict input:  [[4708, 156, 161, 4, 3, 14160]]\n",
      "predict input:  [[156, 161, 4, 3, 14160, 662]]\n",
      "predict input:  [[161, 4, 3, 14160, 662, 7]]\n",
      "predict input:  [[4, 3, 14160, 662, 7, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> mr silence off </s> <s> xenial forgotten a </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 684]]\n",
      "predict input:  [[1, 1, 1, 3, 684, 10]]\n",
      "predict input:  [[1, 1, 3, 684, 10, 7]]\n",
      "predict input:  [[1, 3, 684, 10, 7, 61]]\n",
      "predict input:  [[3, 684, 10, 7, 61, 4]]\n",
      "<h> <h> <h> <h> <h> <h> <s> searching in a heart </s> </h>\n",
      "predict input:  [[1, 1, 1, 1, 1, 1]]\n",
      "predict input:  [[1, 1, 1, 1, 1, 3]]\n",
      "predict input:  [[1, 1, 1, 1, 3, 242]]\n",
      "predict input:  [[1, 1, 1, 3, 242, 5269]]\n",
      "predict input:  [[1, 1, 3, 242, 5269, 13045]]\n",
      "predict input:  [[1, 3, 242, 5269, 13045, 4]]\n",
      "predict input:  [[3, 242, 5269, 13045, 4, 3]]\n",
      "predict input:  [[242, 5269, 13045, 4, 3, 1352]]\n",
      "predict input:  [[5269, 13045, 4, 3, 1352, 3418]]\n",
      "predict input:  [[13045, 4, 3, 1352, 3418, 14]]\n",
      "predict input:  [[4, 3, 1352, 3418, 14, 158]]\n",
      "predict input:  [[3, 1352, 3418, 14, 158, 8]]\n",
      "predict input:  [[1352, 3418, 14, 158, 8, 57]]\n",
      "predict input:  [[3418, 14, 158, 8, 57, 2042]]\n",
      "predict input:  [[14, 158, 8, 57, 2042, 4]]\n",
      "predict input:  [[158, 8, 57, 2042, 4, 3]]\n",
      "predict input:  [[8, 57, 2042, 4, 3, 117]]\n",
      "predict input:  [[57, 2042, 4, 3, 117, 174]]\n",
      "predict input:  [[2042, 4, 3, 117, 174, 1899]]\n",
      "predict input:  [[4, 3, 117, 174, 1899, 1432]]\n",
      "predict input:  [[3, 117, 174, 1899, 1432, 4]]\n",
      "predict input:  [[117, 174, 1899, 1432, 4, 3]]\n",
      "predict input:  [[174, 1899, 1432, 4, 3, 248]]\n",
      "predict input:  [[1899, 1432, 4, 3, 248, 790]]\n",
      "predict input:  [[1432, 4, 3, 248, 790, 667]]\n",
      "predict input:  [[4, 3, 248, 790, 667, 20]]\n",
      "predict input:  [[3, 248, 790, 667, 20, 9]]\n",
      "predict input:  [[248, 790, 667, 20, 9, 3086]]\n",
      "predict input:  [[790, 667, 20, 9, 3086, 4]]\n",
      "predict input:  [[667, 20, 9, 3086, 4, 3]]\n",
      "<h> <h> <h> <h> <h> <h> <s> haikus thrive spews </s> <s> worlds breathtaking is first to our herself </s> <s> why much unless shades </s> <s> does any everyone with my chin </s> <s> we\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    rnn_haiku = generate_haiku(rnn_model_small, tokenizer, [HAIKU_BEGIN] * (NGRAM_SIZE - 1), index_to_embedding, 30, is_rnn=True)\n",
    "    print(rnn_haiku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h> <h> <h> <h> <h> <h> <s> leave for a newfound </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> vegas k from a j </s> <s> around my eyes remain </s> <s> the verge sun pass </s> <s> gucci de from noise </s> <s> the natural to beat\n",
      "<h> <h> <h> <h> <h> <h> <s> if it's haiku </s> <s> you can know you stared </s> <s> their all your gaze swims mist </s> <s> trust must a </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> a ribbon hound </s> <s> only is eternal a black itch </s> <s> leaves souls nett </s> <s> ephemeral with shadowy </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> a dead man bliss </s> <s> nobody special great up </s> <s> search pains true </s> <s> i see its see all </s> <s> haiku out and i simply\n",
      "<h> <h> <h> <h> <h> <h> <s> a crisp eyes slowly stronger </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> man your heart </s> <s> a good breath it is where feels </s> <s> you can cry them </s> <s> what a rotten </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> these falls shakes of wind </s> <s> her bare lips racing </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> emphasis matters </s> <s> me really my life </s> <s> rage to crazy know </s> <s> drowning all maybe and yesterday </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> maybe left the same spring </s> <s> this is weird </s> <s> shooting ballerinas </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> sleeping is super </s> <s> i know that i growing i know </s> <s> a monochrome of you knew </s> <s> all you are called invisible fun </s> <s>\n",
      "<h> <h> <h> <h> <h> <h> <s> the golden of near </s> <s> mountains like his wet </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> she's life life up go </s> <s> crown elevated </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> i are nice reprimand </s> <s> which with the trees around mine </s> <s> a terrible of my soul </s> <s> about this much of false </s> <s> it's\n",
      "<h> <h> <h> <h> <h> <h> <s> while a seven horizon </s> <s> happy life of grace </s> <s> a smelly patty </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> huh from you said with me </s> <s> i found past eyes back </s> <s> the longest moon just </s> <s> does a taste every face </s> <s> if\n",
      "<h> <h> <h> <h> <h> <h> <s> obscured reality spots </s> <s> you'd i love you </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> your balls are bulging </s> <s> venture still tho </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> chaos hates courage </s> <s> waste a struggle of your skin </s> <s> tall splinter of bed </s> <s> but exist a good </s> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> maybe find us it's </s> <s> this is nudging is echo </s> <s> dimming morning leaves accordingly </s> </h>\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    rnn_large_haiku = generate_haiku(rnn_model_large, tokenizer, [HAIKU_BEGIN] * (NGRAM_SIZE - 1), index_to_embedding, 30, is_rnn=True)\n",
    "    print(rnn_large_haiku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    greedy_ffnn = generate_haiku_greedy(feed_forward_model, tokenizer, index_to_embedding, word_to_syllable)\n",
    "    print(greedy_ffnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h> <h> <h> <h> <h> <h> <s> times all are told to </s> <s> the cat are wonderful on </s> <s> procrastination </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> an struggles face back </s> <s> to hold so goddess with my </s> <s> rhythms falls flying with </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> perennial air cool </s> <s> a lineage sound of the current </s> <s> came between cool through </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> off behind quiet the </s> <s> our doubt haze feathers of birds </s> <s> summer harsh upwards </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> rising stream to breathe </s> <s> dead she reflection of the </s> <s> internal has true </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> soda without catch </s> <s> superstitious and meaning </s> <s> water bombarding </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> happy ever bleed </s> <s> you knew miss us for the </s> <s> familiar is but </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> she are good in calm </s> <s> i try to flee up for age </s> <s> daylight red open </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> beckons sometimes all </s> <s> heaved corpse of cream and ears down </s> <s> loom undeterred on </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> like these hidden friends </s> <s> superstitious times severing </s> <s> there pass in my smile </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> normally being week reach </s> <s> my spirit knows cold fill each </s> <s> such toe of life of </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> why didn't it can move </s> <s> maybe more final slow peace </s> <s> ranch of satan cats </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> my minds is full more </s> <s> falls feathers fills everywhere </s> <s> light social got a </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> pop one innocence </s> <s> fainted swine pointless is i </s> <s> furry boom with my soul </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> rituals the garbage </s> <s> him with a machine ceiling </s> <s> feasting bug boom and </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> in a drink have box </s> <s> it's check on meet you say stop </s> <s> everyone dreaming </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> rough gift in rudolph </s> <s> just poo his more chance again </s> <s> he squirrels into part </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> trump all on a chair </s> <s> dorsal grows leaves with midair </s> <s> tomorrow to a </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> are poetry he set </s> <s> if i prepare too pledge why </s> <s> i want you no chance </s> </h> </h> </h> </h> </h> </h>\n",
      "<h> <h> <h> <h> <h> <h> <s> gentle buckets hands </s> <s> waiting on the night sky night </s> <s> here's life in death and </s> </h> </h> </h> </h> </h> </h>\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    greedy_rnn_small = generate_haiku_greedy(rnn_model_small, tokenizer, index_to_embedding, word_to_syllable, is_rnn=True)\n",
    "    print(greedy_rnn_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    greedy_rnn_large = generate_haiku_greedy(rnn_model_large, tokenizer, index_to_embedding, word_to_syllable, is_rnn=True)\n",
    "    print(greedy_rnn_large)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
